{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67afef39-1b41-4f83-8e4a-52390f7dcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "cleaned_data = pd.read_csv(\"Adult_clean.csv\")\n",
    "\n",
    "# --- split training and testing set (80/20) ---\n",
    "# shuffle data\n",
    "shuffled_data = cleaned_data.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# split data by index\n",
    "split_idx = int(0.8 * len(shuffled_data))\n",
    "train = shuffled_data.iloc[:split_idx].copy()\n",
    "test  = shuffled_data.iloc[split_idx:].copy()\n",
    "\n",
    "# define income vs other feature\n",
    "income   = \"income\"\n",
    "\n",
    "features = []\n",
    "for col in cleaned_data.columns:\n",
    "    if col != \"income\":\n",
    "        features.append(col)\n",
    "        \n",
    "\n",
    "# --- Naive Bayes model with income as single parent ---\n",
    "# calculate prior over income\n",
    "income_count = train[income].value_counts()\n",
    "train_len = len(train)\n",
    "\n",
    "# p_income: income_value -> probability\n",
    "p_income = (income_count / train_len).to_dict() \n",
    "\n",
    "# states for each feature\n",
    "feature_state = {}\n",
    "for f in features:\n",
    "    val = train[f].unique()\n",
    "    feature_state[f] = sorted(val)\n",
    "income_state  = sorted(train[income].unique())\n",
    "\n",
    "# CPT: CPT[feature][income_value][feature_value] = probability\n",
    "CPT = {}\n",
    "for f in features:\n",
    "    CPT[f] = {}\n",
    "    val_f = feature_state[f]\n",
    "\n",
    "    for i in income_state:\n",
    "        # find rows where income = i\n",
    "        income_group = train[train[income] == i]\n",
    "        total_i = len(income_group)\n",
    "\n",
    "        # freq of each value of feature f within a income group\n",
    "        f_given_i = income_group[f].value_counts()\n",
    "\n",
    "        # MLE estimate\n",
    "        p_v_given_i = {}\n",
    "        for v in val_f:\n",
    "            count_vy = f_given_i.get(v, 0)\n",
    "            if total_i > 0:\n",
    "                p_v_given_i[v] = count_vy / total_i\n",
    "            else:\n",
    "                # if there is no obs for income value\n",
    "                p_v_given_i[v] = 0.0\n",
    "\n",
    "        CPT[f][i] = p_v_given_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a5389-7baf-4da5-98b2-cd3905ed34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9026c9d-f6d1-4fb8-931c-26dafc4c4fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      " Improved Bayesian Network Results\n",
      "====================================\n",
      "Accuracy: 0.7781\n",
      "\n",
      "Confusion Matrix (income states):\n",
      "       <=50K  >50K\n",
      "<=50K   7006   420\n",
      ">50K    1748   595\n",
      "\n",
      "Log-Likelihood: -272051.10812160466\n",
      "Parameters: 259\n",
      "BIC: 546840.6716685322\n",
      "Sparse CPT cells:\n",
      "  age_bin: 0 sparse cells\n",
      "  education: 0 sparse cells\n",
      "  workclass: 0 sparse cells\n",
      "  occupation: 0 sparse cells\n",
      "  hours_bin: 0 sparse cells\n",
      "  income: 0 sparse cells\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"Adult_clean.csv\")\n",
    "\n",
    "target = \"income\"\n",
    "nodes = df.columns.tolist()\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN/TEST SPLIT (80/20)\n",
    "# ============================================================\n",
    "shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split = int(0.8 * len(shuffled))\n",
    "train = shuffled.iloc[:split].copy()\n",
    "test  = shuffled.iloc[split:].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 3. IMPROVED BAYESIAN NETWORK STRUCTURE\n",
    "# ============================================================\n",
    "parents = {\n",
    "    \"age_bin\": [],\n",
    "    \"education\": [\"age_bin\"],\n",
    "    \"workclass\": [\"education\"],\n",
    "    \"occupation\": [\"education\"],\n",
    "    \"hours_bin\": [\"education\"],\n",
    "    \"income\": [\"occupation\", \"hours_bin\"]\n",
    "}\n",
    "\n",
    "# helper: list of states for each variable\n",
    "states = {col: sorted(df[col].unique()) for col in df.columns}\n",
    "\n",
    "# ============================================================\n",
    "# 4. CPT LEARNING FUNCTION\n",
    "# ============================================================\n",
    "def learn_cpt(train, child, parents, laplace=1.0):\n",
    "    \"\"\"\n",
    "    Compute CPT: P(child | parents) using Laplace smoothing.\n",
    "    Returns: dict: parents_combo_tuple → {child_state: prob}\n",
    "    \"\"\"\n",
    "    child_states = states[child]\n",
    "\n",
    "    if len(parents) == 0:\n",
    "        # root node: estimate P(child)\n",
    "        counts = train[child].value_counts()\n",
    "        total = len(train)\n",
    "        cpt = {}\n",
    "        for cs in child_states:\n",
    "            cpt[()] = cpt.get((), {})\n",
    "            cpt[()][cs] = (counts.get(cs, 0) + laplace) / (total + laplace * len(child_states))\n",
    "        return cpt\n",
    "\n",
    "    # parent combos\n",
    "    parent_states = [states[p] for p in parents]\n",
    "    parent_combos = list(product(*parent_states))\n",
    "\n",
    "    cpt = {}\n",
    "\n",
    "    for combo in parent_combos:\n",
    "        subset = train.copy()\n",
    "        for p, val in zip(parents, combo):\n",
    "            subset = subset[subset[p] == val]\n",
    "\n",
    "        total = len(subset)\n",
    "        counts = subset[child].value_counts()\n",
    "\n",
    "        cpt[combo] = {}\n",
    "        for cs in child_states:\n",
    "            cpt[combo][cs] = (counts.get(cs, 0) + laplace) / (total + laplace * len(child_states))\n",
    "\n",
    "    return cpt\n",
    "\n",
    "# ============================================================\n",
    "# 5. LEARN CPTs FOR ALL NODES\n",
    "# ============================================================\n",
    "CPTs = {}\n",
    "for child in parents:\n",
    "    CPTs[child] = learn_cpt(train, child, parents[child], laplace=1.0)\n",
    "\n",
    "# ============================================================\n",
    "# 6. INFERENCE: P(income | evidence) for test rows\n",
    "# ============================================================\n",
    "def predict_income(row):\n",
    "    inc_states = states[\"income\"]\n",
    "    scores = {}\n",
    "\n",
    "    for inc in inc_states:\n",
    "        score = 1.0\n",
    "\n",
    "        # likelihood: compute joint probability (up to a constant)\n",
    "        for node in parents:\n",
    "            pa = parents[node]\n",
    "            if pa == []:\n",
    "                # root node\n",
    "                probs = CPTs[node][()]\n",
    "                score *= probs[row[node]]\n",
    "            else:\n",
    "                # find parent values tuple\n",
    "                combo = tuple(row[p] for p in pa)\n",
    "                probs = CPTs[node].get(combo, None)\n",
    "                if probs is None:\n",
    "                    # unseen combo → assign tiny probability\n",
    "                    score *= 1e-9\n",
    "                else:\n",
    "                    score *= probs[row[node]]\n",
    "\n",
    "        # override child's income value\n",
    "        # force income = inc for its CPT\n",
    "        combo_inc = tuple(row[p] for p in parents[\"income\"])\n",
    "        score *= CPTs[\"income\"][combo_inc][inc]\n",
    "\n",
    "        scores[inc] = score\n",
    "\n",
    "    # normalize\n",
    "    total = sum(scores.values())\n",
    "    for k in scores:\n",
    "        scores[k] /= total\n",
    "\n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "# ============================================================\n",
    "# 7. RUN PREDICTIONS\n",
    "# ============================================================\n",
    "test_pred = test.apply(predict_income, axis=1)\n",
    "acc = accuracy_score(test[target], test_pred)\n",
    "\n",
    "print(\"====================================\")\n",
    "print(\" Improved Bayesian Network Results\")\n",
    "print(\"====================================\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. CONFUSION MATRIX\n",
    "# ============================================================\n",
    "cm = confusion_matrix(test[target], test_pred, labels=states[\"income\"])\n",
    "print(\"\\nConfusion Matrix (income states):\")\n",
    "print(pd.DataFrame(cm, index=states[\"income\"], columns=states[\"income\"]))\n",
    "\n",
    "# ============================================================\n",
    "# 9. BIC + CPT SPARSITY\n",
    "# ============================================================\n",
    "def compute_loglik_and_params(train, CPTs, parents):\n",
    "    loglik = 0\n",
    "    params = 0\n",
    "    sparsity = {}\n",
    "\n",
    "    for node in parents:\n",
    "        cpt = CPTs[node]\n",
    "        pa = parents[node]\n",
    "        node_states = states[node]\n",
    "        parent_states_list = [states[p] for p in pa] if pa else [[]]\n",
    "\n",
    "        combos = list(cpt.keys())\n",
    "        sparsity[node] = 0\n",
    "\n",
    "        for combo in combos:\n",
    "            for ns in node_states:\n",
    "                p = cpt[combo][ns]\n",
    "                if p < 1e-12:\n",
    "                    sparsity[node] += 1\n",
    "                params += 1\n",
    "\n",
    "    # compute LL\n",
    "    for _, row in train.iterrows():\n",
    "        for node in parents:\n",
    "            pa = parents[node]\n",
    "            if pa:\n",
    "                combo = tuple(row[p] for p in pa)\n",
    "            else:\n",
    "                combo = ()\n",
    "            p = CPTs[node][combo][row[node]]\n",
    "            if p < 1e-12:\n",
    "                p = 1e-12\n",
    "            loglik += np.log(p)\n",
    "\n",
    "    return loglik, params, sparsity\n",
    "\n",
    "loglik, params, sparsity = compute_loglik_and_params(train, CPTs, parents)\n",
    "bic = -2 * loglik + params * np.log(len(train))\n",
    "\n",
    "print(\"\\nLog-Likelihood:\", loglik)\n",
    "print(\"Parameters:\", params)\n",
    "print(\"BIC:\", bic)\n",
    "print(\"Sparse CPT cells:\")\n",
    "for n, s in sparsity.items():\n",
    "    print(f\"  {n}: {s} sparse cells\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18883043-9b11-406a-9f66-598b1f784ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7794042378953834\n",
      "\n",
      "Confusion matrix:\n",
      "[[6968  446]\n",
      " [1709  646]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"Adult_clean.csv\")\n",
    "\n",
    "# Make sure all features are strings (categorical)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "parents = {\n",
    "    'age_bin': [],\n",
    "    'education': ['age_bin'],\n",
    "    'workclass': ['education'],\n",
    "    'occupation': ['education'],\n",
    "    'hours_bin': ['occupation'],\n",
    "    'income': ['hours_bin', 'occupation']\n",
    "}\n",
    "\n",
    "nodes = list(parents.keys())\n",
    "\n",
    "\n",
    "CPT = {}\n",
    "\n",
    "def get_counts(subset, col):\n",
    "    \"\"\"Return a normalized probability table for a single variable.\"\"\"\n",
    "    counts = subset[col].value_counts()\n",
    "    total = counts.sum()\n",
    "    return {v: counts.get(v, 0) / total for v in subset[col].unique()}\n",
    "\n",
    "for node in nodes:\n",
    "    node_parents = parents[node]\n",
    "    CPT[node] = {}\n",
    "\n",
    "    if len(node_parents) == 0:\n",
    "        # No parents → unconditional distribution\n",
    "        CPT[node][None] = train_df[node].value_counts(normalize=True).to_dict()\n",
    "    else:\n",
    "        # With parents → need conditional distribution\n",
    "        parent_vals = train_df[node_parents].drop_duplicates()\n",
    "\n",
    "        for _, parent_row in parent_vals.iterrows():\n",
    "            key = tuple(parent_row[p] for p in node_parents)\n",
    "            subset = train_df\n",
    "            for p in node_parents:\n",
    "                subset = subset[subset[p] == parent_row[p]]\n",
    "\n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "\n",
    "            dist = subset[node].value_counts(normalize=True).to_dict()\n",
    "            CPT[node][key] = dist\n",
    "\n",
    "\n",
    "def predict_row(row):\n",
    "    \"\"\"Compute P(income | evidence) via BN factorization.\"\"\"\n",
    "\n",
    "    # Test both income states\n",
    "    income_states = list(CPT['income'][list(CPT['income'].keys())[0]].keys())\n",
    "    scores = {}\n",
    "\n",
    "    for income_state in income_states:\n",
    "        prob = 1.0\n",
    "\n",
    "        # Evaluate BN probability product\n",
    "        for node in nodes:\n",
    "            node_parents = parents[node]\n",
    "\n",
    "            # income gets manually set to the tested state\n",
    "            if node == 'income':\n",
    "                node_value = income_state\n",
    "            else:\n",
    "                node_value = row[node]\n",
    "\n",
    "            # Parent key\n",
    "            if len(node_parents) == 0:\n",
    "                key = None\n",
    "            else:\n",
    "                key = tuple(income_state if p=='income' else row[p] for p in node_parents)\n",
    "            if key not in CPT[node] or node_value not in CPT[node][key]:\n",
    "                prob *= 1e-9  # smoothing for missing combinations\n",
    "            else:\n",
    "                prob *= CPT[node][key][node_value]\n",
    "\n",
    "        scores[income_state] = prob\n",
    "\n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "\n",
    "test_df['pred'] = test_df.apply(predict_row, axis=1)\n",
    "\n",
    "acc = accuracy_score(test_df['income'], test_df['pred'])\n",
    "cm = confusion_matrix(test_df['income'], test_df['pred'])\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71786361-e23f-49fc-80b8-b7d061325e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
